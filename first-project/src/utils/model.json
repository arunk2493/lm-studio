{
    "model": "",
    "messages": [
        {
            "role": "",
            "content": ""
        }
    ],
    "temperature": 0.7,
    "max_tokens": -1,
    "stream": false
}